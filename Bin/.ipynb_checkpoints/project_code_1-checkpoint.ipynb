{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1.)set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to sepparate the data from the full data sheet since I want to import it using pandas, which can't read the inturupting headers. To sepparate the data I created a scipt called extractheaders.sh and saved just the end of the headeline numbers in a file that I've loaded bellow to start. I focused on grabbing these numbers because I know they are the start to each data section and I can then count that each header is 13 lines long and I can choose to skip these lines and extract only the data for that section by noting the line the next header starts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load number lines for end of headers from full data \n",
    "headerlines=pd.read_table('header_ends.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12\n",
      "0   538\n",
      "1  1064\n",
      "2  1590\n",
      "3  2116\n",
      "4  2642\n"
     ]
    }
   ],
   "source": [
    "print(headerlines.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variable for the length of the unseparated data called sabrina.dat\n",
    "#setting this variable with the len() function would make your code easier to manage if you change anything about your data\n",
    "#even if you don't change your data, it will make your code more reusable\n",
    "length_of_file=12624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this while loop should load your data\n",
    "#skipped rows is equal to the number of rows at the bottom of the file to skip\n",
    "skipped_footer = length_of_file\n",
    "#table will store the each table of data as an item in a list\n",
    "table = []\n",
    "#header row is equal to the row that contains the header for the data\n",
    "header_row = 10\n",
    "#this loops will continue to go, until all the data has been read\n",
    "while skipped_footer > 0:\n",
    "    #shifts the skipped footer down the length of a table \n",
    "    skipped_footer -= 526\n",
    "    #dataframe is the dataframe that contains the data\n",
    "    dataframe = pd.read_table('sabrina.dat', sep='\\s+', header=header_row, skipfooter = skipped_footer, engine='python')\n",
    "    #appends the dataframe to the list\n",
    "    table.append(dataframe)\n",
    "    #save the list of data chunks\n",
    "    dataframe.to_csv('/Users/sabrinadesoto/Desktop/Sab_Final_Project/Bin/data_chunks_list.csv', delimiter=',')\n",
    "    #shifts the header row to the next table in the data\n",
    "    header_row += 523\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here's your data!\n",
    "#this is table number 4\n",
    "table[0].head()\n",
    "\n",
    "#save this table as a file\n",
    "table[0].to_csv('/Users/sabrinadesoto/Desktop/Data_chunk1.csv', delimiter='\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write loop to print separate tables (like above^) for each data section\n",
    "for row in ('sabrina.dat'):\n",
    "    table_1=pd.read_table('sabrina.dat', sep='\\s+', skiprows=13, skipfooter=length_of_file-527, engine='python')\n",
    "    \n",
    "    if row == 'headerlines':\n",
    "        return(table_1)\n",
    "    else:\n",
    "        None\n",
    "print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#attempt 2 for writting loop to print separate tables (like above^) for each data section\n",
    "for row in ('sabrina.dat'):\n",
    "    if row == 'headerlines':\n",
    "        table = (pd.read_table('sabrina.dat', sep='\\s+', nrows=512, engine='python'))\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attempt 3 for writting loop to print data \n",
    "def print_tables(lines):\n",
    "    headerlines=pd.read_table('header_ends.dat')\n",
    "    \n",
    "    if lines in 'sabrina.dat' & 'headerlines':\n",
    "        return(pd.read_table('sabrina.dat', sep='\\s+', nrows=512))\n",
    "    \n",
    "    else:\n",
    "        None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_tables('sabrina.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.)resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#resample data to split it into (30 min ave. chunks)\n",
    "#necessary for individual plots?-import of pandas and creat new table?\n",
    "\n",
    "#using reg.ex:\n",
    "#grab amplitude data\n",
    "re_ampl=for ampl in readings:\n",
    "    if re.search('Ampl(Jy) FLAGGED', readings)\n",
    "    print r\n",
    "\n",
    "#how do I sepparate for each chunk?\n",
    "\n",
    "#using iloc:\n",
    "testload.iloc[:10,2:4] #example the first 10 rows for columns 2 & 3\n",
    "#how do I know row numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grab phase data\n",
    "re_phase=for phase in readings:\n",
    "    if re.search('Phase', readings)\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creat smaller data set of just phase & amplitude \n",
    "resampled=readings[['re_amp','re_phase']]\n",
    "resampled.head\n",
    "\n",
    "#add collumn for channel (just counts 1-512)\n",
    "resampled['Channel']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3.)make phase diagrams\n",
    "Spike in the amplitude is the detection we care about. From that we can look at the phase pts that go with that spike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot Channel vs. phase/ampl. for all times\n",
    "#use multi-pannel plots stacked on eachother\n",
    "\n",
    "#subplot 1-phase\n",
    "plt.subplot (2,1,1)\n",
    "#need to limit input to each chunk of data\n",
    "plt.plot(resampled.Channel, resampled.Phase)\n",
    "plt.ylabel('Phase')\n",
    "plt.tittle('Phase Diagram')\n",
    "#blue line\n",
    "\n",
    "#subplot 2-ampl.\n",
    "plt.subplot (2,2,1)\n",
    "plt.plot(resampled.Channel, resampled.Ampl(Jy))\n",
    "plt.xlabel('Channel')\n",
    "plt.ylabel('Amplitude(Jy)')\n",
    "#green x scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot for all chunks of data\n",
    "resampled.plot(subplots=True, figsize = (10, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4.)isolate detection data pts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find max amplitude(=detect spike)\n",
    "print(re_ampl.max())#can I include this in detection function?\n",
    "\n",
    "def detection_phases(resampled):\n",
    "'''finds coorisponding phase pts. for amplitude spikes indicating a detection'''\n",
    "#write loop that for all aplitudes greater than () will return the corresponding phase\n",
    "    if re_ampl > #value?:\n",
    "        return re_phase\n",
    "\n",
    "#loop returns only detection phases \n",
    "for data in resampled:\n",
    "    detection=detection_phases(data)\n",
    "    if detection:\n",
    "        print(detection_phases(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5.)compare detection for all 30min ave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creat table from all detection data\n",
    "\n",
    "#first row is the 30minute data collection chunks\n",
    "\n",
    "#function to grab times from data: \n",
    "def get_time(record):\n",
    "    '''Return (hour,minute) as string'''\n",
    "    \n",
    "    #assign variable to capture pattern and capturing\n",
    "    cp='\\s([\\s][0-9]|[0-9][0-9])\\s([\\s][0-9]|[0-9][0-9])\\s30.0'#adjust to include day&ave?\n",
    "    p=re.search(cp, record)\n",
    "    \n",
    "    #loop for research to return above pattern\n",
    "    if p:\n",
    "        return p.group(1), p.group(2)\n",
    "\n",
    "#add loop so that no-matches aren't printed\n",
    "for r in readings:\n",
    "    #assign variable to function\n",
    "    time=get_time(r)\n",
    "    if time:\n",
    "        print(get_time(r))\n",
    "        \n",
    "#column for each are detection data from step 4\n",
    "#how do I match those detections with a single detection time for each chunk? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6.)do some super handy stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7.)do some way cooler physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
