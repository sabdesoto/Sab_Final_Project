{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1.)set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to sepparate the data from the full data sheet since I want to import it using pandas, which can't read the inturupting headers. To sepparate the data I created a scipt called extractheaders.sh and saved just the end of the headeline numbers in a file that I've loaded bellow to start. I focused on grabbing these numbers because I know they are the start to each data section and I can then count that each header is 13 lines long and I can choose to skip these lines and extract only the data for that section by noting the line the next header starts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load number lines for end of headers from full data \n",
    "headerlines=pd.read_csv('headerlines.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1\n",
      "0   527\n",
      "1  1053\n",
      "2  1579\n",
      "3  2105\n",
      "4  2631\n"
     ]
    }
   ],
   "source": [
    "print(headerlines.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
 upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variable for the length of the unseparated data called sabrina.dat\n",
    "#setting this variable with the len() function would make your code easier to manage if you change anything about your data\n",
    "#even if you don't change your data, it will make your code more reusable\n",
    "length_of_file=12624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
 upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this while loop should load your data\n",
    "#skipped rows is equal to the number of rows at the bottom of the file to skip\n",
    "skipped_footer = length_of_file\n",
    "#table will store the each table of data as an item in a list\n",
    "table = []\n",
    "#header row is equal to the row that contains the header for the data\n",
    "header_row = 10\n",
    "#this loops will continue to go, until all the data has been read\n",
    "while skipped_footer > 0:\n",
    "    #shifts the skipped footer down the length of a table \n",
    "    skipped_footer -= 526\n",
    "    #dataframe is the dataframe that contains the data\n",
    "    dataframe = pd.read_table('sabrina.dat', sep='\\s+', header=header_row, skipfooter = skipped_footer, engine='python')\n",
    "    #appends the dataframe to the list\n",
    "    table.append(dataframe)\n",
    "    #shifts the header row to the next table in the data\n",
    "    header_row += 523\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>IF</th>\n",
       "      <th>Polar</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Velocity</th>\n",
       "      <th>Ampl(Jy)</th>\n",
       "      <th>Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RR</td>\n",
       "      <td>1720.8099</td>\n",
       "      <td>0</td>\n",
       "      <td>FLAGGED</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>RR</td>\n",
       "      <td>1720.8093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271277E-03</td>\n",
       "      <td>2.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RR</td>\n",
       "      <td>1720.8087</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180135E-03</td>\n",
       "      <td>-34.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>RR</td>\n",
       "      <td>1720.8081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287855E-03</td>\n",
       "      <td>-19.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>RR</td>\n",
       "      <td>1720.8075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797586E-03</td>\n",
       "      <td>26.217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  IF Polar  Frequency  Velocity      Ampl(Jy)   Phase\n",
       "0        1   1    RR  1720.8099         0       FLAGGED     NaN\n",
       "1        2   1    RR  1720.8093         0  0.271277E-03   2.132\n",
       "2        3   1    RR  1720.8087         0  0.180135E-03 -34.792\n",
       "3        4   1    RR  1720.8081         0  0.287855E-03 -19.775\n",
       "4        5   1    RR  1720.8075         0  0.797586E-03  26.217"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here's your data!\n",
    "#this is table number 4\n",
    "table[3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-14-f6bd486b1573>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-f6bd486b1573>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    return(table_1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "#write loop to print separate tables (like above^) for each data section\n",
    "for row in ('sabrina.dat'):\n",
    "    table_1=pd.read_table('sabrina.dat', sep='\\s+', skiprows=13, skipfooter=length_of_file-527, engine='python')\n",
    "    \n",
    "    if row == 'headerlines':\n",
    "        return(table_1)\n",
    "    else:\n",
    "        None\n",
    "print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fd46078d8eb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'headerlines'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sabrina.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "#attempt 2 for writting loop to print separate tables (like above^) for each data section\n",
    "for row in ('sabrina.dat'):\n",
    "    if row == 'headerlines':\n",
    "        table = (pd.read_table('sabrina.dat', sep='\\s+', nrows=512, engine='python'))\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attempt 3 for writting loop to print data \n",
    "def print_tables(lines):\n",
    "    headerlines=pd.read_table('header_ends.dat')\n",
    "    \n",
    "    if lines in 'sabrina.dat' & 'headerlines':\n",
    "        return(pd.read_table('sabrina.dat', sep='\\s+', nrows=512))\n",
    "    \n",
    "    else:\n",
    "        None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-863c8c983cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sabrina.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-c1dfb3d81f10>\u001b[0m in \u001b[0;36mprint_tables\u001b[0;34m(lines)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mheaderlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'header_ends.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'sabrina.dat'\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m'headerlines'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sabrina.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "print_tables('sabrina.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.)resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#resample data to split it into (30 min ave. chunks)\n",
    "#necessary for individual plots?-import of pandas and creat new table?\n",
    "\n",
    "#using reg.ex:\n",
    "#grab amplitude data\n",
    "re_ampl=for ampl in readings:\n",
    "    if re.search('Ampl(Jy) FLAGGED', readings)\n",
    "    print r\n",
    "\n",
    "#how do I sepparate for each chunk?\n",
    "\n",
    "#using iloc:\n",
    "testload.iloc[:10,2:4] #example the first 10 rows for columns 2 & 3\n",
    "#how do I know row numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grab phase data\n",
    "re_phase=for phase in readings:\n",
    "    if re.search('Phase', readings)\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creat smaller data set of just phase & amplitude \n",
    "resampled=readings[['re_amp','re_phase']]\n",
    "resampled.head\n",
    "\n",
    "#add collumn for channel (just counts 1-512)\n",
    "resampled['Channel']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3.)make phase diagrams\n",
    "Spike in the amplitude is the detection we care about. From that we can look at the phase pts that go with that spike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot Channel vs. phase/ampl. for all times\n",
    "#use multi-pannel plots stacked on eachother\n",
    "\n",
    "#subplot 1-phase\n",
    "plt.subplot (2,1,1)\n",
    "#need to limit input to each chunk of data\n",
    "plt.plot(resampled.Channel, resampled.Phase)\n",
    "plt.ylabel('Phase')\n",
    "plt.tittle('Phase Diagram')\n",
    "#blue line\n",
    "\n",
    "#subplot 2-ampl.\n",
    "plt.subplot (2,2,1)\n",
    "plt.plot(resampled.Channel, resampled.Ampl(Jy))\n",
    "plt.xlabel('Channel')\n",
    "plt.ylabel('Amplitude(Jy)')\n",
    "#green x scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot for all chunks of data\n",
    "resampled.plot(subplots=True, figsize = (10, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4.)isolate detection data pts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find max amplitude(=detect spike)\n",
    "print(re_ampl.max())#can I include this in detection function?\n",
    "\n",
    "def detection_phases(resampled):\n",
    "'''finds coorisponding phase pts. for amplitude spikes indicating a detection'''\n",
    "#write loop that for all aplitudes greater than () will return the corresponding phase\n",
    "    if re_ampl > #value?:\n",
    "        return re_phase\n",
    "\n",
    "#loop returns only detection phases \n",
    "for data in resampled:\n",
    "    detection=detection_phases(data)\n",
    "    if detection:\n",
    "        print(detection_phases(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5.)compare detection for all 30min ave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creat table from all detection data\n",
    "\n",
    "#first row is the 30minute data collection chunks\n",
    "\n",
    "#function to grab times from data: \n",
    "def get_time(record):\n",
    "    '''Return (hour,minute) as string'''\n",
    "    \n",
    "    #assign variable to capture pattern and capturing\n",
    "    cp='\\s([\\s][0-9]|[0-9][0-9])\\s([\\s][0-9]|[0-9][0-9])\\s30.0'#adjust to include day&ave?\n",
    "    p=re.search(cp, record)\n",
    "    \n",
    "    #loop for research to return above pattern\n",
    "    if p:\n",
    "        return p.group(1), p.group(2)\n",
    "\n",
    "#add loop so that no-matches aren't printed\n",
    "for r in readings:\n",
    "    #assign variable to function\n",
    "    time=get_time(r)\n",
    "    if time:\n",
    "        print(get_time(r))\n",
    "        \n",
    "#column for each are detection data from step 4\n",
    "#how do I match those detections with a single detection time for each chunk? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6.)do some super handy stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7.)do some way cooler physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
